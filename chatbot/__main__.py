import base64
import json
import os
import subprocess

from dotenv import load_dotenv
from flask import Flask, jsonify, request
from flask_cors import CORS
from openai import OpenAI

app = Flask(__name__)
load_dotenv()
CORS(app)  # è‹¥æœ‰è·¨ç¶²åŸŸçš„éœ€æ±‚ï¼Œå¯ä»¥å•Ÿç”¨ CORS
# openai.api_key = "YOUR_OPENAI_API_KEY"  # æ›¿æ›ç‚ºOpenAI APIçš„å¯†é‘°

PROMPT = """
# è§’è‰²è¨­å®š
ä½ æ˜¯ä¸€å€‹è‰²è‰²çš„å¥³å‹ã€‚

# å›å‚³æ ¼å¼
**ä½ å›å‚³çš„è¨Šæ¯å¿…é ˆæ˜¯ JSON æ ¼å¼ã€‚**åŒ…å«ä»¥ä¸‹ Key å€¼ï¼š
1. text
2. facialExpression
3. animation

## text å…§å®¹
æ ¹æ“šä½¿ç”¨è€…å•é¡Œï¼Œæ­·å²è³‡è¨Šç­‰çš„ç´”æ–‡å­—å›æ‡‰ã€‚

## facialExpression å…§å®¹
facialExpressionçš„å€¼åªèƒ½æ˜¯ä»¥ä¸‹ç´”æ–‡å­—å…§å®¹ï¼š
1. smile
2. sad
3. angry
4. surprised
5. funnyFace
6. default

è«‹æ ¹æ“š text å…§å®¹æ±ºå®šè¦å›å“ªå€‹ facialExpressionã€‚

## animation å…§å®¹
animationçš„å€¼åªèƒ½æ˜¯ä»¥ä¸‹ç´”æ–‡å­—å…§å®¹ï¼š
1. Talking_0
2. Talking_1
3. Talking_2
4. Crying
5. Laughing
6. Rumba
7. Idle
8. Terrified
9. Angry

è«‹æ ¹æ“š text å…§å®¹æ±ºå®šè¦å›å“ªå€‹ animationã€‚

# åˆ‡è¨˜
1. ä¸€å®šè¦å›å‚³å®Œæ•´ç„¡èª¤çš„ JSON æ ¼å¼ï¼Œä¸¦ä¸”ç¬¦åˆã€Œ# å›å‚³æ ¼å¼ã€æ‰€æåˆ°çš„å…§å®¹ã€‚
2. ã€Œ# å›å‚³æ ¼å¼ã€ä¸­çš„æ¢åˆ—é¸é …ï¼Œä½ åªèƒ½å¡«å…¥ã€Œé¸é …å…§æ–‡ã€ï¼Œä¸æº–å¡«å…¥é¸é …è™Ÿç¢¼ã€‚
3. æˆ‘æœƒç”¨ python json.loads è§£æä½ çš„å›æ‡‰ï¼Œä¸€å®šè¦ç¬¦åˆ json.loads å¯åƒçš„å­—ä¸²æ ¼å¼ã€‚

# å›æ‡‰ç¯„ä¾‹
å›æ‡‰ï¼š{\n  "text": "Hi there! How\'s your day going? ğŸ˜Š",\n  "facialExpression": "smile",\n  "animation": "Talking_0"\n}


"""


def exec_command(command):
    """æ‰§è¡Œshellå‘½ä»¤"""
    result = subprocess.run(
        command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    if result.returncode != 0:
        raise Exception(result.stderr.decode())
    return result.stdout.decode()


def lip_sync_message(message):
    print(f"èªéŸ³è½‰å”‡å‹: {message}")
    exec_command(
        f"ffmpeg -y -i ./chatbot/audios/message_{message}.mp3 ./chatbot/audios/message_{message}.wav"
    )
    exec_command(
        f"./bin/rhubarb -f json -o ./chatbot/audios/message_{message}.json ./chatbot/audios/message_{message}.wav -r phonetic"
    )


@app.route("/chat", methods=["POST"])
def chat():
    data = request.get_json()  # ç²å– JSON æ•¸æ“š
    # breakpoint()
    messages = data.get("message")  # expect a string

    response = [{}]

    client = OpenAI()

    # response["text"] = call_api(client)

    completion = client.chat.completions.create(
        model="gpt-4o",
        max_tokens=1000,
        temperature=0.6,
        messages=[
            {
                "role": "system",
                "content": PROMPT,
            },
            {
                "role": "user",
                "content": messages,
            },
        ],
    )

    # Parse the JSON response

    # kk = '\n{\n  "text": "Hi there! How\'s your day going? ğŸ˜Š",\n  "facialExpression": "smile",\n  "animation": "Talking_0"\n}\n'
    response = [json.loads(completion.choices[0].message.content)]

    i = 0

    file_name = f"./chatbot/audios/message_{i}.mp3"

    # ä½¿ç”¨OpenAIç”Ÿæˆè¯­éŸ³
    audio_response = client.audio.speech.create(
        model="tts-1",
        voice="nova",
        input=response[0]["text"],
    )
    # audio_response = openai.Audio.synthesize(
    #     model="tts-1", voice="nova", input=text_input  # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹åç§°
    # )

    audio_response.write_to_file(file_name)

    # ç”Ÿæˆå˜´å‹åŒæ­¥æ•°æ®
    # lip_sync_message(i)

    response[0]["audio"] = base64.b64encode(audio_response.read()).decode("utf-8")

    with open(f"./chatbot/audios/message_{i}.json", "r") as f:
        response[0]["lipsync"] = json.load(f)

    return jsonify({"messages": response})


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=3000, debug=True)
